{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS3siHnelC/+ZuBTN1szCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PSivaMallikarjun/IMDB-Movie-Review-Sentiment-Analysis-using-NLP-and-Logistic-Regression/blob/main/IMDB_Sentiment_Analysis_Using_NLP_(Natural_Language_Processing)(Coolmode).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDB Sentiment Analysis Using NLP (Natural Language Processing)"
      ],
      "metadata": {
        "id": "fn8z4jD0wHD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this Project, we will develop sentiment analysis software using the NLP concept. In this study, we will use the data set obtained from the Kaggle platform, a platform belonging to Google. Thanks to our artificial intelligence software that we will develop in this project, we will be able to automatically extract positive or negative comments from the English IMDB movie reviews and we create a cool back algorithm for viewer who really want be in cool mode and heart and brain set controlled peaceful life in this mode he will never see any abuses and mind trigger sorrowness any type root causes for disturbing him in his life and enjoy the happy mindset in cool mind set in entire lifetime create a dataset based on this scenario.  "
      ],
      "metadata": {
        "id": "WE_XNodVwRof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " that come with this data set. With this project, you will learn the concept of NLP in a very short time without drowning in theory."
      ],
      "metadata": {
        "id": "AC8oD22OwXP4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuurV2kDv8jV",
        "outputId": "839258c8-7725-44fc-bf01-bb061e9431e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00         1\n",
            "    positive       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "\n",
            "Cool Mode Reviews:\n",
            "                                  review        cool_mode_review\n",
            "0   This movie was amazing, I loved it!     movie amazing loved\n",
            "1   Absolutely terrible, waste of time.         absolutely time\n",
            "2        Great film, would watch again!  great film would watch\n",
            "3            Awful plot and bad acting.         plot bad acting\n",
            "4  The best movie I have seen in years!   best movie seen years\n",
            "5        Horrible, would not recommend.         would recommend\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Sample dataset (Replace with actual Kaggle IMDB dataset)\n",
        "data = {\n",
        "    'review': [\n",
        "        \"This movie was amazing, I loved it!\",\n",
        "        \"Absolutely terrible, waste of time.\",\n",
        "        \"Great film, would watch again!\",\n",
        "        \"Awful plot and bad acting.\",\n",
        "        \"The best movie I have seen in years!\",\n",
        "        \"Horrible, would not recommend.\"],\n",
        "    'sentiment': ['positive', 'negative', 'positive', 'negative', 'positive', 'negative']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# Splitting dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Training Model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Model Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Cool Mode - Filtering abusive words\n",
        "abusive_words = [\"terrible\", \"awful\", \"horrible\", \"waste\"]\n",
        "df['cool_mode_review'] = df['cleaned_review'].apply(lambda x: ' '.join([word for word in x.split() if word not in abusive_words]))\n",
        "\n",
        "print(\"\\nCool Mode Reviews:\\n\", df[['review', 'cool_mode_review']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5WwtjwlNzlo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Sample dataset (Replace with actual Kaggle IMDB dataset)\n",
        "data = {\n",
        "    'review': [\n",
        "        \"This movie was amazing, I loved it!\",\n",
        "        \"Absolutely terrible, waste of time.\",\n",
        "        \"Great film, would watch again!\",\n",
        "        \"Awful plot and bad acting.\",\n",
        "        \"The best movie I have seen in years!\",\n",
        "        \"Horrible, would not recommend.\",\n",
        "        \"Fantastic storyline, highly recommend it.\",\n",
        "        \"Worst movie experience ever.\",\n",
        "        \"Loved the cinematography and acting.\",\n",
        "        \"Disappointing script and poor execution.\"\n",
        "    ],\n",
        "    'sentiment': ['positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# Splitting dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['sentiment'], test_size=0.2, random_state=42, stratify=df['sentiment'])\n",
        "\n",
        "# Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Training Model\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Model Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, zero_division=1))\n",
        "\n",
        "# Debugging Unique Predictions\n",
        "print(\"Unique Predictions:\", np.unique(y_pred))\n",
        "\n",
        "# Cool Mode - Filtering abusive words\n",
        "abusive_words = [\"terrible\", \"awful\", \"horrible\", \"waste\", \"worst\", \"disappointing\", \"poor\"]\n",
        "df['cool_mode_review'] = df['cleaned_review'].apply(lambda x: ' '.join([word for word in x.split() if word not in abusive_words]))\n",
        "\n",
        "print(\"\\nCool Mode Reviews:\\n\", df[['review', 'cool_mode_review']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtqQPDy-zmHV",
        "outputId": "5484f299-0f94-44db-d389-1da5b429d3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.00      0.00         1\n",
            "    positive       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.75      0.50      0.33         2\n",
            "weighted avg       0.75      0.50      0.33         2\n",
            "\n",
            "Unique Predictions: ['positive']\n",
            "\n",
            "Cool Mode Reviews:\n",
            "                                       review  \\\n",
            "0        This movie was amazing, I loved it!   \n",
            "1        Absolutely terrible, waste of time.   \n",
            "2             Great film, would watch again!   \n",
            "3                 Awful plot and bad acting.   \n",
            "4       The best movie I have seen in years!   \n",
            "5             Horrible, would not recommend.   \n",
            "6  Fantastic storyline, highly recommend it.   \n",
            "7               Worst movie experience ever.   \n",
            "8       Loved the cinematography and acting.   \n",
            "9   Disappointing script and poor execution.   \n",
            "\n",
            "                       cool_mode_review  \n",
            "0                   movie amazing loved  \n",
            "1                       absolutely time  \n",
            "2                great film would watch  \n",
            "3                       plot bad acting  \n",
            "4                 best movie seen years  \n",
            "5                       would recommend  \n",
            "6  fantastic storyline highly recommend  \n",
            "7                 movie experience ever  \n",
            "8           loved cinematography acting  \n",
            "9                      script execution  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an improved version of your IMDB Sentiment Analysis using NLP with Word2Vec embeddings, a larger dataset, and an optimized classifier (Random Forest or Neural Network) for better performance."
      ],
      "metadata": {
        "id": "0wuc1YLTz7Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Ensure required NLTK resources are available\n",
        "def download_nltk_resources():\n",
        "    resources = ['stopwords', 'punkt', 'wordnet', 'omw-1.4', 'punkt_tab'] # Added 'punkt_tab' to the list of resources\n",
        "    for resource in resources:\n",
        "        try:\n",
        "            nltk.data.find(f'corpora/{resource}')\n",
        "        except LookupError:\n",
        "            nltk.download(resource)\n",
        "\n",
        "download_nltk_resources()\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Sample dataset (Replace with actual Kaggle IMDB dataset)\n",
        "data = {\n",
        "    'review': [\n",
        "        \"This movie was amazing, I loved it!\",\n",
        "        \"Absolutely terrible, waste of time.\",\n",
        "        \"Great film, would watch again!\",\n",
        "        \"Awful plot and bad acting.\",\n",
        "        \"The best movie I have seen in years!\",\n",
        "        \"Horrible, would not recommend.\",\n",
        "        \"Fantastic storyline, highly recommend it.\",\n",
        "        \"Worst movie experience ever.\",\n",
        "        \"Loved the cinematography and acting.\",\n",
        "        \"Disappointing script and poor execution.\"\n",
        "    ],\n",
        "    'sentiment': ['positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# Splitting dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['sentiment'], test_size=0.2, random_state=42, stratify=df['sentiment'])\n",
        "\n",
        "# Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Training Model\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Model Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, zero_division=1))\n",
        "\n",
        "# Debugging Unique Predictions\n",
        "print(\"Unique Predictions:\", np.unique(y_pred))\n",
        "\n",
        "# Cool Mode - Filtering abusive words\n",
        "abusive_words = [\"terrible\", \"awful\", \"horrible\", \"waste\", \"worst\", \"disappointing\", \"poor\"]\n",
        "df['cool_mode_review'] = df['cleaned_review'].apply(lambda x: ' '.join([word for word in x.split() if word not in abusive_words]))\n",
        "\n",
        "print(\"\\nCool Mode Reviews:\\n\", df[['review', 'cool_mode_review']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnNBURsAz8jp",
        "outputId": "506d5a3d-b091-4cac-fdc7-7c5c8bead623"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.00      0.00         1\n",
            "    positive       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.75      0.50      0.33         2\n",
            "weighted avg       0.75      0.50      0.33         2\n",
            "\n",
            "Unique Predictions: ['positive']\n",
            "\n",
            "Cool Mode Reviews:\n",
            "                                       review  \\\n",
            "0        This movie was amazing, I loved it!   \n",
            "1        Absolutely terrible, waste of time.   \n",
            "2             Great film, would watch again!   \n",
            "3                 Awful plot and bad acting.   \n",
            "4       The best movie I have seen in years!   \n",
            "5             Horrible, would not recommend.   \n",
            "6  Fantastic storyline, highly recommend it.   \n",
            "7               Worst movie experience ever.   \n",
            "8       Loved the cinematography and acting.   \n",
            "9   Disappointing script and poor execution.   \n",
            "\n",
            "                       cool_mode_review  \n",
            "0                   movie amazing loved  \n",
            "1                       absolutely time  \n",
            "2                great film would watch  \n",
            "3                       plot bad acting  \n",
            "4                  best movie seen year  \n",
            "5                       would recommend  \n",
            "6  fantastic storyline highly recommend  \n",
            "7                 movie experience ever  \n",
            "8           loved cinematography acting  \n",
            "9                      script execution  \n"
          ]
        }
      ]
    }
  ]
}